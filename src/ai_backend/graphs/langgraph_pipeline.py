# # src/ai_backend/graphs/langgraph_pipeline.py

# from langgraph import
# from ai_backend.services.llm_service import generate_response

# # Initialize LangGraph
# graph = graph()


# @graph.node()
# def process_input(input_text: str) -> str:
#     """Processes input text using LLM."""
#     return generate_response(input_text)


# def run_graph(input_text: str):
#     return graph.run("process_input", input_text)
